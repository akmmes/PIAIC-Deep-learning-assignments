{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Concrete strength prediction Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV64ck0XEQo-"
      },
      "source": [
        "# PIAIC Deep Learning Assignment\n",
        "\n",
        "H M Sarmad Khan\n",
        "PIAIC_AI_101225"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxsM1lJnWYUX"
      },
      "source": [
        "# Assignment: \n",
        "Compresive Strength Concrete Problem\n",
        "\n",
        "**Abstract:**\n",
        "\n",
        "Concrete is the most important material in civil engineering. The concrete compressive strength (concrete strength to bear the load) is a highly nonlinear function of age and ingredients.\n",
        "\n",
        "**WORKFLOW :** \n",
        "\n",
        "Load Data\n",
        "\n",
        "Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "Standardized the Input Variables. Hint: Centeralized the data Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
        "\n",
        "Train the Model with Epochs (100) and validate it\n",
        "\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "Evaluation Step\n",
        "\n",
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnYR0Hf9WQsg"
      },
      "source": [
        "#upload the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofFSZOoHWVZQ"
      },
      "source": [
        "#import all required libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models,layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "rQoxIMoZWhbP",
        "outputId": "9ab23467-f6f9-40b5-a645-5f7d50f198bb"
      },
      "source": [
        "#to upload the Datset File that we use in training\n",
        "from google.colab import files\n",
        "upload=files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c26b63b8-6d7b-4e0d-8ad1-1d4dfd477022\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c26b63b8-6d7b-4e0d-8ad1-1d4dfd477022\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving compresive_strength_concrete.csv to compresive_strength_concrete (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "gsgd9qedWo1r",
        "outputId": "176b8d52-5972-4ca1-a336-a742956e2c84"
      },
      "source": [
        "df=pd.read_csv('/content/compresive_strength_concrete.csv')#reading the file \n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
              "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
              "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
              "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
              "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
              "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
              "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
              "      <th>Age (day)</th>\n",
              "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement (component 1)(kg in a m^3 mixture)  ...  Concrete compressive strength(MPa, megapascals) \n",
              "0                                      540.0  ...                                             79.99\n",
              "1                                      540.0  ...                                             61.89\n",
              "2                                      332.5  ...                                             40.27\n",
              "3                                      332.5  ...                                             41.05\n",
              "4                                      198.6  ...                                             44.30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ayz86_jZWsIJ",
        "outputId": "21939230-d1db-4287-df9d-f00b86bdbf0a"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1030 entries, 0 to 1029\n",
            "Data columns (total 9 columns):\n",
            " #   Column                                                 Non-Null Count  Dtype  \n",
            "---  ------                                                 --------------  -----  \n",
            " 0   Cement (component 1)(kg in a m^3 mixture)              1030 non-null   float64\n",
            " 1   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  1030 non-null   float64\n",
            " 2   Fly Ash (component 3)(kg in a m^3 mixture)             1030 non-null   float64\n",
            " 3   Water  (component 4)(kg in a m^3 mixture)              1030 non-null   float64\n",
            " 4   Superplasticizer (component 5)(kg in a m^3 mixture)    1030 non-null   float64\n",
            " 5   Coarse Aggregate  (component 6)(kg in a m^3 mixture)   1030 non-null   float64\n",
            " 6   Fine Aggregate (component 7)(kg in a m^3 mixture)      1030 non-null   float64\n",
            " 7   Age (day)                                              1030 non-null   int64  \n",
            " 8   Concrete compressive strength(MPa, megapascals)        1030 non-null   float64\n",
            "dtypes: float64(8), int64(1)\n",
            "memory usage: 72.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCRssTnnWtmw"
      },
      "source": [
        "df['Age (day)']=df.select_dtypes('int64').astype('float64')#converting age column to float64"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB6fY6idWviQ"
      },
      "source": [
        "test_val=(30/100)*len(df)#get the value that r 30% of Dataset\n",
        "train_val=(50/100)*len(df)#get the value that r 50% of Dataset\n",
        "val_val=(20/100)*len(df)#get the value that r 20% of Dataset\n",
        "\n",
        "test_data=df.loc[len(df)-test_val: ,:'Age (day)']#separating the test data from dataset, pick the data from last of dataset\n",
        "test_labels=df.loc[len(df)-test_val: ,'Concrete compressive strength(MPa, megapascals) ']#separating the test labels from dataset\n",
        "\n",
        "remaining_data=df.loc[:len(df)-test_val,:'Age (day)']#to store the remaing datset for further processing\n",
        "remaining_labels=df.loc[:len(df)-test_val,'Concrete compressive strength(MPa, megapascals) ']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPnWvvTpWyHx"
      },
      "source": [
        "mean=df.mean(axis=0)\n",
        "std=df.std(axis=0)\n",
        "\n",
        "remaining_data-=mean\n",
        "remaining_data/=std\n",
        "\n",
        "test_data-=mean\n",
        "test_data/=std"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArsctRKuW0ZV"
      },
      "source": [
        "train_data = remaining_data.loc[ :test_val]\n",
        "train_labels = remaining_labels.loc[ :test_val]\n",
        "\n",
        "val_data=remaining_data.loc[test_val:]\n",
        "val_labels=remaining_labels.loc[test_val:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sk2RGr7W2W6",
        "outputId": "c33a8020-fede-44be-a4c0-4a5f870d35c4"
      },
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Dense(36,activation='relu',input_shape=(8,)))\n",
        "model.add(layers.Dense(36,activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "\n",
        "\n",
        "model.fit(train_data,train_labels,epochs=150,batch_size=100,validation_data=(val_data,val_labels))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "4/4 [==============================] - 3s 170ms/step - loss: 2109.8686 - mae: 42.2642 - val_loss: 1356.5934 - val_mae: 32.8854\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2009.9702 - mae: 41.2343 - val_loss: 1336.1583 - val_mae: 32.5806\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2016.5909 - mae: 41.3236 - val_loss: 1315.5648 - val_mae: 32.2715\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2005.1787 - mae: 41.0667 - val_loss: 1297.6787 - val_mae: 31.9997\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1930.6287 - mae: 40.2849 - val_loss: 1278.5962 - val_mae: 31.7150\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1941.4856 - mae: 40.4060 - val_loss: 1258.9408 - val_mae: 31.4111\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1858.1860 - mae: 39.4856 - val_loss: 1238.3407 - val_mae: 31.0959\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1839.0965 - mae: 39.2069 - val_loss: 1217.1776 - val_mae: 30.7678\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1839.6638 - mae: 39.0496 - val_loss: 1195.1876 - val_mae: 30.4240\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1827.3901 - mae: 38.9266 - val_loss: 1171.4974 - val_mae: 30.0548\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1681.9484 - mae: 37.2073 - val_loss: 1148.5646 - val_mae: 29.6874\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1666.0259 - mae: 37.0142 - val_loss: 1123.7467 - val_mae: 29.2919\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1695.3632 - mae: 37.3412 - val_loss: 1099.9647 - val_mae: 28.9043\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1616.1080 - mae: 36.2547 - val_loss: 1074.3542 - val_mae: 28.4866\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1577.5894 - mae: 35.6556 - val_loss: 1047.7715 - val_mae: 28.0548\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1564.2228 - mae: 35.4060 - val_loss: 1021.5013 - val_mae: 27.6138\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1482.2865 - mae: 34.5493 - val_loss: 994.5850 - val_mae: 27.1601\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1420.0778 - mae: 33.6859 - val_loss: 966.9213 - val_mae: 26.6866\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1371.4683 - mae: 33.0231 - val_loss: 938.8997 - val_mae: 26.2014\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1291.2622 - mae: 32.0812 - val_loss: 911.4811 - val_mae: 25.7163\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1264.9999 - mae: 31.4462 - val_loss: 882.8979 - val_mae: 25.2082\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1173.3737 - mae: 30.3211 - val_loss: 851.7848 - val_mae: 24.6478\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1154.4096 - mae: 30.0012 - val_loss: 822.2015 - val_mae: 24.1176\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1074.3856 - mae: 28.6186 - val_loss: 794.1046 - val_mae: 23.5929\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1037.1517 - mae: 28.1657 - val_loss: 763.9567 - val_mae: 23.0318\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 965.8480 - mae: 27.0195 - val_loss: 736.5233 - val_mae: 22.5028\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 895.7975 - mae: 25.7973 - val_loss: 705.6358 - val_mae: 21.9107\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 907.5592 - mae: 25.6507 - val_loss: 677.9409 - val_mae: 21.3711\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 826.8498 - mae: 24.7191 - val_loss: 652.0484 - val_mae: 20.8654\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 821.2703 - mae: 24.3550 - val_loss: 624.9934 - val_mae: 20.3330\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 760.6672 - mae: 23.1224 - val_loss: 596.1436 - val_mae: 19.7595\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 705.0987 - mae: 21.8799 - val_loss: 566.6738 - val_mae: 19.1819\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 622.3523 - mae: 20.5082 - val_loss: 539.7957 - val_mae: 18.6475\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 594.0618 - mae: 20.1875 - val_loss: 510.5321 - val_mae: 18.0520\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 534.0300 - mae: 18.8178 - val_loss: 483.6378 - val_mae: 17.5217\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 498.5526 - mae: 18.1764 - val_loss: 459.3592 - val_mae: 17.0366\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 476.4718 - mae: 17.7664 - val_loss: 439.2629 - val_mae: 16.6281\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 429.5112 - mae: 16.5977 - val_loss: 417.8664 - val_mae: 16.2047\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 407.4701 - mae: 16.1529 - val_loss: 397.5848 - val_mae: 15.7949\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 377.0675 - mae: 15.5429 - val_loss: 375.9455 - val_mae: 15.3532\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 339.0799 - mae: 14.7526 - val_loss: 358.8354 - val_mae: 14.9877\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 341.3500 - mae: 14.8505 - val_loss: 339.0685 - val_mae: 14.5619\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 326.3951 - mae: 14.5844 - val_loss: 322.7944 - val_mae: 14.2092\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 316.2050 - mae: 14.3509 - val_loss: 308.8904 - val_mae: 13.9094\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 309.9256 - mae: 14.2375 - val_loss: 302.7179 - val_mae: 13.7751\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 311.5105 - mae: 14.3758 - val_loss: 302.1089 - val_mae: 13.7580\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 286.3491 - mae: 13.7815 - val_loss: 298.3278 - val_mae: 13.6792\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 292.8996 - mae: 13.9469 - val_loss: 286.9086 - val_mae: 13.4404\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 273.9685 - mae: 13.4692 - val_loss: 275.2973 - val_mae: 13.2013\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 281.3977 - mae: 13.6836 - val_loss: 272.1151 - val_mae: 13.1406\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 267.3916 - mae: 13.3846 - val_loss: 261.6598 - val_mae: 12.9236\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 269.4703 - mae: 13.4546 - val_loss: 255.6782 - val_mae: 12.8125\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 261.0968 - mae: 13.3013 - val_loss: 259.7292 - val_mae: 12.9049\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 252.7803 - mae: 13.1651 - val_loss: 258.7748 - val_mae: 12.8961\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 241.4977 - mae: 12.7890 - val_loss: 251.9930 - val_mae: 12.7662\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 247.4739 - mae: 13.0033 - val_loss: 252.1713 - val_mae: 12.7790\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 252.5049 - mae: 13.1008 - val_loss: 246.5963 - val_mae: 12.6799\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 228.9363 - mae: 12.4974 - val_loss: 244.1690 - val_mae: 12.6345\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 237.7805 - mae: 12.8479 - val_loss: 238.8910 - val_mae: 12.5390\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 237.1396 - mae: 12.7564 - val_loss: 238.8364 - val_mae: 12.5436\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 234.9031 - mae: 12.5803 - val_loss: 237.5974 - val_mae: 12.5376\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 227.1652 - mae: 12.4671 - val_loss: 242.6143 - val_mae: 12.6451\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 223.1748 - mae: 12.4186 - val_loss: 247.1121 - val_mae: 12.7429\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 224.0123 - mae: 12.5101 - val_loss: 245.6151 - val_mae: 12.7147\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 219.1415 - mae: 12.3414 - val_loss: 248.5155 - val_mae: 12.7855\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 220.8440 - mae: 12.3494 - val_loss: 250.7145 - val_mae: 12.8425\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 218.0356 - mae: 12.1799 - val_loss: 252.8031 - val_mae: 12.8870\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 213.6708 - mae: 12.0297 - val_loss: 250.5259 - val_mae: 12.8431\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 215.5398 - mae: 12.1838 - val_loss: 248.5562 - val_mae: 12.8228\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 211.8721 - mae: 12.1529 - val_loss: 246.6522 - val_mae: 12.7900\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 201.7003 - mae: 11.8091 - val_loss: 243.6359 - val_mae: 12.7411\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 197.5919 - mae: 11.5880 - val_loss: 243.3074 - val_mae: 12.7369\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 211.8687 - mae: 12.1189 - val_loss: 244.5504 - val_mae: 12.7613\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 193.2410 - mae: 11.5241 - val_loss: 252.0195 - val_mae: 12.9144\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 202.0848 - mae: 11.7397 - val_loss: 252.2137 - val_mae: 12.9188\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 195.6108 - mae: 11.6895 - val_loss: 248.5122 - val_mae: 12.8575\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 197.3896 - mae: 11.7241 - val_loss: 247.7645 - val_mae: 12.8494\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 196.2194 - mae: 11.5325 - val_loss: 245.1700 - val_mae: 12.8076\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 199.2664 - mae: 11.8115 - val_loss: 245.9405 - val_mae: 12.8198\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 184.0167 - mae: 11.2710 - val_loss: 247.3269 - val_mae: 12.8668\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 184.2074 - mae: 11.3798 - val_loss: 248.0040 - val_mae: 12.8752\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 182.8065 - mae: 11.1615 - val_loss: 250.0937 - val_mae: 12.9178\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 176.2200 - mae: 11.0218 - val_loss: 256.4249 - val_mae: 13.0326\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 183.1591 - mae: 11.2160 - val_loss: 258.2230 - val_mae: 13.0645\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 181.2297 - mae: 11.1997 - val_loss: 252.3770 - val_mae: 12.9661\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 180.8592 - mae: 11.1820 - val_loss: 251.7576 - val_mae: 12.9519\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 180.2311 - mae: 11.1120 - val_loss: 255.2567 - val_mae: 13.0081\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 170.9420 - mae: 10.8357 - val_loss: 256.9860 - val_mae: 13.0480\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 182.6629 - mae: 11.2020 - val_loss: 259.4281 - val_mae: 13.0923\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 180.6757 - mae: 11.1151 - val_loss: 259.1220 - val_mae: 13.0972\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 180.9110 - mae: 11.2922 - val_loss: 257.0730 - val_mae: 13.0567\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 173.4071 - mae: 10.8844 - val_loss: 256.5260 - val_mae: 13.0639\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 175.5995 - mae: 11.0074 - val_loss: 258.3658 - val_mae: 13.0982\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 172.0954 - mae: 10.9868 - val_loss: 261.0678 - val_mae: 13.1472\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 171.6007 - mae: 10.8169 - val_loss: 261.9434 - val_mae: 13.1575\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 170.4953 - mae: 10.8745 - val_loss: 260.9854 - val_mae: 13.1540\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 171.9521 - mae: 10.9719 - val_loss: 262.2481 - val_mae: 13.2162\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 165.1565 - mae: 10.5761 - val_loss: 261.1614 - val_mae: 13.2089\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 159.5380 - mae: 10.5492 - val_loss: 259.0888 - val_mae: 13.1634\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 175.6852 - mae: 11.0858 - val_loss: 260.0422 - val_mae: 13.1804\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 163.8064 - mae: 10.5606 - val_loss: 261.9911 - val_mae: 13.2378\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 161.4916 - mae: 10.5025 - val_loss: 264.8791 - val_mae: 13.2931\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 172.4712 - mae: 10.9311 - val_loss: 263.8773 - val_mae: 13.2855\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 161.5369 - mae: 10.5135 - val_loss: 262.9233 - val_mae: 13.2854\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 159.9954 - mae: 10.4965 - val_loss: 262.7772 - val_mae: 13.2870\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 154.0514 - mae: 10.2601 - val_loss: 268.2122 - val_mae: 13.3721\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 156.3917 - mae: 10.2842 - val_loss: 266.6926 - val_mae: 13.3583\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 155.7927 - mae: 10.3610 - val_loss: 267.4806 - val_mae: 13.3704\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 157.6149 - mae: 10.3992 - val_loss: 268.6377 - val_mae: 13.3693\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 153.2478 - mae: 10.1797 - val_loss: 267.3612 - val_mae: 13.3512\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 148.4608 - mae: 10.0576 - val_loss: 265.4573 - val_mae: 13.3097\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 155.2682 - mae: 10.2063 - val_loss: 267.9991 - val_mae: 13.3406\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 152.9140 - mae: 10.1932 - val_loss: 268.6067 - val_mae: 13.3480\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 152.8032 - mae: 10.1453 - val_loss: 268.5081 - val_mae: 13.3743\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 156.4852 - mae: 10.3182 - val_loss: 265.5707 - val_mae: 13.2946\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 150.8574 - mae: 10.1843 - val_loss: 269.8415 - val_mae: 13.3692\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 154.1600 - mae: 10.2583 - val_loss: 268.9903 - val_mae: 13.3610\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 152.3200 - mae: 10.1266 - val_loss: 266.8940 - val_mae: 13.3268\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 154.2512 - mae: 10.2053 - val_loss: 265.9168 - val_mae: 13.3133\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 146.2282 - mae: 9.8121 - val_loss: 265.1816 - val_mae: 13.2853\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 150.7029 - mae: 10.1359 - val_loss: 265.6195 - val_mae: 13.2921\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 145.4334 - mae: 9.9003 - val_loss: 269.6389 - val_mae: 13.3937\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 142.7826 - mae: 9.8598 - val_loss: 271.5822 - val_mae: 13.4323\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 143.6606 - mae: 9.7983 - val_loss: 271.1483 - val_mae: 13.4060\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 139.5725 - mae: 9.6388 - val_loss: 272.9529 - val_mae: 13.4575\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 150.3294 - mae: 10.1031 - val_loss: 271.4985 - val_mae: 13.4271\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 141.9511 - mae: 9.7267 - val_loss: 271.9457 - val_mae: 13.4238\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 147.0333 - mae: 9.8434 - val_loss: 268.9474 - val_mae: 13.3516\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 143.5893 - mae: 9.8763 - val_loss: 265.4731 - val_mae: 13.2680\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 142.7654 - mae: 9.7036 - val_loss: 265.3489 - val_mae: 13.2437\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 149.9474 - mae: 10.0498 - val_loss: 263.9786 - val_mae: 13.2138\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 145.5578 - mae: 9.8537 - val_loss: 266.0025 - val_mae: 13.2634\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 141.8501 - mae: 9.7393 - val_loss: 265.4034 - val_mae: 13.2549\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 139.6639 - mae: 9.6494 - val_loss: 264.5446 - val_mae: 13.2444\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 146.2160 - mae: 9.8355 - val_loss: 263.7767 - val_mae: 13.2146\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 145.7885 - mae: 9.8181 - val_loss: 263.0794 - val_mae: 13.2072\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 139.8148 - mae: 9.6795 - val_loss: 265.8018 - val_mae: 13.2556\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 139.5612 - mae: 9.5693 - val_loss: 264.5883 - val_mae: 13.2490\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 139.3757 - mae: 9.5510 - val_loss: 265.2246 - val_mae: 13.2708\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 133.5862 - mae: 9.4465 - val_loss: 264.1885 - val_mae: 13.2543\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 130.2152 - mae: 9.3134 - val_loss: 265.7923 - val_mae: 13.2816\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 136.8778 - mae: 9.5296 - val_loss: 266.5632 - val_mae: 13.2883\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 144.5236 - mae: 9.9055 - val_loss: 265.6853 - val_mae: 13.2738\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 145.3626 - mae: 9.8989 - val_loss: 266.3168 - val_mae: 13.2638\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 139.0433 - mae: 9.4954 - val_loss: 266.4538 - val_mae: 13.2658\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 142.8636 - mae: 9.8720 - val_loss: 267.7012 - val_mae: 13.2882\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 138.9582 - mae: 9.5735 - val_loss: 269.1204 - val_mae: 13.3230\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 136.9563 - mae: 9.5112 - val_loss: 268.0746 - val_mae: 13.3075\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 128.4741 - mae: 9.1876 - val_loss: 268.7504 - val_mae: 13.3392\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 132.9606 - mae: 9.3561 - val_loss: 268.3181 - val_mae: 13.3143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff5f4aa28d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz7SrA-RW7jY"
      },
      "source": [
        "def build_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(36,activation='relu',input_shape=(8,)))\n",
        "  model.add(layers.Dense(36,activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgybqDLiW-po",
        "outputId": "f69ab317-7680-4c70-dc5a-70ac6c64b644"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(remaining_data) // k\n",
        "num_epochs = 80\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        " print('processing fold #', i)\n",
        "\n",
        " # Prepare the validation data: data from partition # k\n",
        " val_data = remaining_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " val_targets = remaining_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "\n",
        " # Prepare the training data: data from all other partitions\n",
        " partial_train_data = np.concatenate([remaining_data[:i * num_val_samples],remaining_data[(i + 1) * num_val_samples:]],axis=0)\n",
        " partial_train_targets = np.concatenate([remaining_labels[:i * num_val_samples],remaining_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        " # Build the Keras model (already compiled)\n",
        "\n",
        "\n",
        " model = build_model()\n",
        " # Train the model (in silent mode, verbose=0)\n",
        " history = model.fit(partial_train_data, partial_train_targets,validation_data=(val_data, val_targets),epochs=num_epochs, batch_size=5)\n",
        " mae_history = history.history['val_mae']\n",
        " all_mae_histories.append(mae_history)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1178.5262 - mae: 30.3779 - val_loss: 2017.3936 - val_mae: 41.8494\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 701.1290 - mae: 21.9183 - val_loss: 1062.3975 - val_mae: 27.9414\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 310.4242 - mae: 13.6829 - val_loss: 603.5052 - val_mae: 19.5753\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 210.0589 - mae: 11.4949 - val_loss: 447.8260 - val_mae: 16.4104\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 163.9597 - mae: 10.1133 - val_loss: 416.8099 - val_mae: 16.1101\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 148.5146 - mae: 9.7851 - val_loss: 441.6183 - val_mae: 16.6498\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 150.2552 - mae: 9.6229 - val_loss: 468.3213 - val_mae: 17.0671\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 139.6077 - mae: 9.2594 - val_loss: 493.1289 - val_mae: 17.3940\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 131.5717 - mae: 8.8543 - val_loss: 520.4308 - val_mae: 17.7316\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 130.4895 - mae: 8.9325 - val_loss: 535.4086 - val_mae: 17.8687\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 103.2555 - mae: 8.0943 - val_loss: 519.0491 - val_mae: 17.4416\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 126.0725 - mae: 8.5096 - val_loss: 560.3290 - val_mae: 18.0415\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 100.2686 - mae: 8.0006 - val_loss: 558.7869 - val_mae: 18.0057\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 117.9095 - mae: 8.2787 - val_loss: 562.4532 - val_mae: 18.0558\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 122.4945 - mae: 8.3630 - val_loss: 570.8259 - val_mae: 18.1670\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 107.3712 - mae: 8.0303 - val_loss: 560.6863 - val_mae: 18.0454\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 90.4298 - mae: 7.5404 - val_loss: 542.9815 - val_mae: 17.7186\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 123.7724 - mae: 8.5291 - val_loss: 620.0322 - val_mae: 18.7430\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 108.4544 - mae: 7.8710 - val_loss: 598.1633 - val_mae: 18.4955\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 100.3411 - mae: 7.4943 - val_loss: 620.5782 - val_mae: 18.8187\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 101.6871 - mae: 7.4993 - val_loss: 580.2818 - val_mae: 18.1660\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 92.9328 - mae: 7.3806 - val_loss: 605.2886 - val_mae: 18.5591\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 101.6951 - mae: 7.5473 - val_loss: 552.7854 - val_mae: 17.8980\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 74.4667 - mae: 6.7971 - val_loss: 539.0106 - val_mae: 17.6554\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 87.6935 - mae: 7.2009 - val_loss: 615.1886 - val_mae: 18.7131\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 117.8638 - mae: 8.0542 - val_loss: 587.8597 - val_mae: 18.2519\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 97.7502 - mae: 7.2947 - val_loss: 638.3981 - val_mae: 19.0530\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 94.3907 - mae: 7.3163 - val_loss: 577.4908 - val_mae: 18.1195\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 83.9897 - mae: 6.8562 - val_loss: 552.7607 - val_mae: 17.7446\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 96.1476 - mae: 7.3461 - val_loss: 576.3732 - val_mae: 17.9665\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 84.0302 - mae: 6.6777 - val_loss: 655.5338 - val_mae: 19.1156\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 80.1804 - mae: 6.5954 - val_loss: 558.8218 - val_mae: 17.6656\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 77.0371 - mae: 6.5688 - val_loss: 525.0325 - val_mae: 17.1753\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 69.5044 - mae: 6.2924 - val_loss: 478.1498 - val_mae: 16.5036\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 78.2426 - mae: 6.7221 - val_loss: 558.5135 - val_mae: 17.5276\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 69.3150 - mae: 6.4144 - val_loss: 538.9417 - val_mae: 17.3788\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 80.6452 - mae: 6.8112 - val_loss: 559.1743 - val_mae: 17.5813\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 62.5272 - mae: 5.9776 - val_loss: 468.9300 - val_mae: 16.2874\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 77.0291 - mae: 6.5185 - val_loss: 485.9381 - val_mae: 16.4466\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 64.0376 - mae: 6.1427 - val_loss: 504.6862 - val_mae: 16.8117\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 66.8071 - mae: 6.1608 - val_loss: 500.8463 - val_mae: 16.6985\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 55.3669 - mae: 5.6841 - val_loss: 484.2592 - val_mae: 16.3731\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 55.9052 - mae: 5.6013 - val_loss: 444.0204 - val_mae: 15.7605\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 53.4923 - mae: 5.6182 - val_loss: 436.4828 - val_mae: 15.6167\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.3840 - mae: 5.8050 - val_loss: 503.3918 - val_mae: 16.8315\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 58.4317 - mae: 5.8251 - val_loss: 395.8202 - val_mae: 15.0411\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.4423 - mae: 5.9761 - val_loss: 379.1045 - val_mae: 14.5962\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 52.7325 - mae: 5.5871 - val_loss: 371.6040 - val_mae: 14.4804\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.5548 - mae: 5.5797 - val_loss: 343.8525 - val_mae: 14.0093\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 47.3956 - mae: 5.3402 - val_loss: 359.2834 - val_mae: 14.3058\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 43.9075 - mae: 5.1966 - val_loss: 354.4719 - val_mae: 14.3265\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.5530 - mae: 5.0680 - val_loss: 307.0201 - val_mae: 13.3587\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.7048 - mae: 5.0279 - val_loss: 350.6497 - val_mae: 14.2653\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 39.6666 - mae: 4.8421 - val_loss: 347.3688 - val_mae: 14.2022\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.5203 - mae: 5.0112 - val_loss: 321.6522 - val_mae: 13.5707\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 39.8508 - mae: 4.9885 - val_loss: 286.9111 - val_mae: 12.9047\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.6568 - mae: 4.5881 - val_loss: 308.5682 - val_mae: 13.3836\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.6707 - mae: 4.4193 - val_loss: 300.6099 - val_mae: 13.2634\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.0077 - mae: 4.5629 - val_loss: 279.2765 - val_mae: 12.8200\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.9493 - mae: 4.2925 - val_loss: 254.4753 - val_mae: 12.3507\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.7919 - mae: 4.2660 - val_loss: 250.7192 - val_mae: 12.2531\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.7827 - mae: 4.2495 - val_loss: 252.9291 - val_mae: 12.2192\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 25.9764 - mae: 3.9822 - val_loss: 217.0194 - val_mae: 11.4049\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.0170 - mae: 3.7284 - val_loss: 255.0694 - val_mae: 12.2841\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.5339 - mae: 3.7036 - val_loss: 222.0236 - val_mae: 11.4937\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.8693 - mae: 3.8648 - val_loss: 246.6812 - val_mae: 12.0369\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 25.8743 - mae: 3.9215 - val_loss: 229.7343 - val_mae: 11.6497\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.4256 - mae: 3.6393 - val_loss: 201.2644 - val_mae: 10.9260\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.6569 - mae: 3.5755 - val_loss: 200.8610 - val_mae: 10.9854\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.5295 - mae: 3.7312 - val_loss: 209.3352 - val_mae: 11.0812\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.2564 - mae: 3.4255 - val_loss: 177.1182 - val_mae: 10.3337\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.9263 - mae: 3.4871 - val_loss: 193.4548 - val_mae: 10.6912\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.2623 - mae: 3.3376 - val_loss: 195.1924 - val_mae: 10.8133\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.3841 - mae: 3.4906 - val_loss: 186.6051 - val_mae: 10.5267\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.6224 - mae: 3.2828 - val_loss: 215.9049 - val_mae: 11.2180\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.8423 - mae: 3.3895 - val_loss: 184.1053 - val_mae: 10.4528\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.1002 - mae: 3.3429 - val_loss: 175.6666 - val_mae: 10.3351\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.3370 - mae: 3.2807 - val_loss: 155.2280 - val_mae: 9.8428\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.6325 - mae: 3.2912 - val_loss: 162.8644 - val_mae: 10.0801\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.6543 - mae: 3.1419 - val_loss: 208.2483 - val_mae: 11.0043\n",
            "processing fold # 1\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1703.6995 - mae: 36.9406 - val_loss: 1132.4329 - val_mae: 30.3815\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1118.7167 - mae: 28.5685 - val_loss: 610.3506 - val_mae: 21.2425\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 440.5469 - mae: 16.2574 - val_loss: 287.7952 - val_mae: 14.1579\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 228.2424 - mae: 12.2269 - val_loss: 195.0854 - val_mae: 11.5179\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 214.6036 - mae: 11.7898 - val_loss: 181.6974 - val_mae: 10.9485\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 191.3378 - mae: 11.5663 - val_loss: 179.9013 - val_mae: 10.8131\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 169.2177 - mae: 10.4483 - val_loss: 174.8439 - val_mae: 10.6159\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 163.3823 - mae: 10.8001 - val_loss: 172.5436 - val_mae: 10.5257\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 143.4739 - mae: 9.7299 - val_loss: 167.1255 - val_mae: 10.3049\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 140.0847 - mae: 9.9320 - val_loss: 163.6511 - val_mae: 10.1570\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 147.9516 - mae: 10.1192 - val_loss: 165.2639 - val_mae: 10.2760\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 151.0848 - mae: 10.1215 - val_loss: 163.0931 - val_mae: 10.1485\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 142.5534 - mae: 9.7787 - val_loss: 162.3192 - val_mae: 10.0511\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 137.9821 - mae: 9.6076 - val_loss: 159.0465 - val_mae: 9.8508\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 135.7580 - mae: 9.4498 - val_loss: 163.1169 - val_mae: 10.0473\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 132.1121 - mae: 9.4568 - val_loss: 162.7383 - val_mae: 9.9714\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 128.1251 - mae: 9.2933 - val_loss: 162.5539 - val_mae: 10.1422\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 124.7889 - mae: 9.2054 - val_loss: 159.3194 - val_mae: 9.9389\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 127.9423 - mae: 9.4031 - val_loss: 161.8186 - val_mae: 10.0305\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 119.4592 - mae: 9.1207 - val_loss: 163.7160 - val_mae: 10.1528\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 130.3283 - mae: 9.4321 - val_loss: 162.7464 - val_mae: 10.1797\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 128.2258 - mae: 9.3173 - val_loss: 154.1299 - val_mae: 9.6894\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 124.5005 - mae: 9.1500 - val_loss: 158.9093 - val_mae: 9.8871\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 123.1554 - mae: 9.0451 - val_loss: 155.2894 - val_mae: 9.6534\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 123.1056 - mae: 9.0334 - val_loss: 151.8217 - val_mae: 9.5232\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 111.2074 - mae: 8.4926 - val_loss: 152.9238 - val_mae: 9.5759\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 112.2163 - mae: 8.5999 - val_loss: 145.2621 - val_mae: 9.2764\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 129.6305 - mae: 9.2897 - val_loss: 151.6023 - val_mae: 9.6877\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 120.7690 - mae: 8.9338 - val_loss: 144.4101 - val_mae: 9.3330\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 112.9753 - mae: 8.5740 - val_loss: 148.7433 - val_mae: 9.5850\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 99.7539 - mae: 8.1634 - val_loss: 146.7782 - val_mae: 9.5162\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 90.8910 - mae: 7.7911 - val_loss: 138.2109 - val_mae: 9.0508\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 97.7892 - mae: 7.9559 - val_loss: 137.3983 - val_mae: 9.0530\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 89.9375 - mae: 7.6966 - val_loss: 136.3800 - val_mae: 9.0502\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 94.7793 - mae: 7.8092 - val_loss: 129.0286 - val_mae: 8.6698\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 82.2264 - mae: 7.1055 - val_loss: 133.9388 - val_mae: 9.0072\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 84.6536 - mae: 7.2081 - val_loss: 125.0169 - val_mae: 8.4977\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 77.9512 - mae: 6.9863 - val_loss: 120.7869 - val_mae: 8.2591\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 81.6842 - mae: 7.1547 - val_loss: 121.6869 - val_mae: 8.3057\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 70.9476 - mae: 6.8103 - val_loss: 121.6399 - val_mae: 8.2943\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 70.4932 - mae: 6.5128 - val_loss: 119.9684 - val_mae: 8.1754\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.1298 - mae: 6.0114 - val_loss: 117.4497 - val_mae: 8.0794\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 62.2293 - mae: 6.2539 - val_loss: 119.2658 - val_mae: 8.1259\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 52.6532 - mae: 5.7903 - val_loss: 115.6704 - val_mae: 7.9361\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 53.1709 - mae: 5.7766 - val_loss: 109.3947 - val_mae: 7.5404\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 56.7115 - mae: 5.9531 - val_loss: 111.9152 - val_mae: 7.7926\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 52.4058 - mae: 5.5822 - val_loss: 116.5146 - val_mae: 8.0397\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 48.6292 - mae: 5.3104 - val_loss: 123.4016 - val_mae: 8.4086\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 47.2025 - mae: 5.1715 - val_loss: 110.8587 - val_mae: 7.7600\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 45.7874 - mae: 5.1096 - val_loss: 106.8723 - val_mae: 7.6230\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.5896 - mae: 5.2988 - val_loss: 101.4250 - val_mae: 7.2453\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.1644 - mae: 5.3284 - val_loss: 106.1777 - val_mae: 7.6252\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 43.6176 - mae: 5.1020 - val_loss: 104.1711 - val_mae: 7.4802\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.3975 - mae: 4.9183 - val_loss: 97.7473 - val_mae: 7.0895\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 46.1993 - mae: 5.1508 - val_loss: 101.4322 - val_mae: 7.3516\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.0639 - mae: 4.9190 - val_loss: 94.5897 - val_mae: 6.9741\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.8357 - mae: 5.0471 - val_loss: 97.1069 - val_mae: 7.1875\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 37.7545 - mae: 4.7042 - val_loss: 94.6244 - val_mae: 7.0872\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.1237 - mae: 4.4576 - val_loss: 93.4937 - val_mae: 6.9893\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 40.7378 - mae: 4.7766 - val_loss: 98.0006 - val_mae: 7.2284\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.4645 - mae: 4.3720 - val_loss: 94.3562 - val_mae: 7.0768\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.7880 - mae: 4.5973 - val_loss: 101.3143 - val_mae: 7.4971\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.1045 - mae: 4.5826 - val_loss: 92.4002 - val_mae: 6.9978\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.1970 - mae: 4.7286 - val_loss: 90.0272 - val_mae: 6.8403\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.4985 - mae: 4.6743 - val_loss: 89.0036 - val_mae: 6.8560\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.2971 - mae: 4.9099 - val_loss: 90.5044 - val_mae: 6.9341\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.2521 - mae: 4.3301 - val_loss: 87.3921 - val_mae: 6.7132\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 37.1156 - mae: 4.6904 - val_loss: 86.4224 - val_mae: 6.7545\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.6074 - mae: 4.4694 - val_loss: 92.5466 - val_mae: 7.1434\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.2888 - mae: 4.4643 - val_loss: 85.2742 - val_mae: 6.7196\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.2190 - mae: 4.4819 - val_loss: 84.0125 - val_mae: 6.5837\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.5363 - mae: 4.3791 - val_loss: 81.9361 - val_mae: 6.4846\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.2348 - mae: 4.4022 - val_loss: 87.2600 - val_mae: 6.8449\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 40.0981 - mae: 4.6803 - val_loss: 87.1797 - val_mae: 6.9198\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.0878 - mae: 4.3156 - val_loss: 83.1682 - val_mae: 6.6049\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.2170 - mae: 4.1741 - val_loss: 81.2490 - val_mae: 6.5157\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.7907 - mae: 4.3984 - val_loss: 82.9319 - val_mae: 6.6434\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.1836 - mae: 4.6703 - val_loss: 80.1820 - val_mae: 6.4541\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.7596 - mae: 4.2855 - val_loss: 94.0177 - val_mae: 7.3162\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.7323 - mae: 4.3078 - val_loss: 83.3132 - val_mae: 6.7236\n",
            "processing fold # 2\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1522.7708 - mae: 34.4934 - val_loss: 1606.1587 - val_mae: 36.8956\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1126.9804 - mae: 28.8985 - val_loss: 958.9371 - val_mae: 27.2478\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 482.2819 - mae: 17.6923 - val_loss: 428.0664 - val_mae: 17.1800\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 250.3684 - mae: 12.8181 - val_loss: 305.3213 - val_mae: 14.3130\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 206.4303 - mae: 11.7200 - val_loss: 287.8523 - val_mae: 13.8231\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 184.5958 - mae: 11.1506 - val_loss: 278.9754 - val_mae: 13.5654\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 164.2769 - mae: 10.6041 - val_loss: 270.2060 - val_mae: 13.3207\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 146.5437 - mae: 10.0400 - val_loss: 271.2271 - val_mae: 13.3259\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 150.5356 - mae: 9.9435 - val_loss: 268.4045 - val_mae: 13.2334\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 150.5845 - mae: 10.1604 - val_loss: 250.7710 - val_mae: 12.7737\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 147.7052 - mae: 10.0645 - val_loss: 248.3533 - val_mae: 12.7142\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 138.0440 - mae: 9.6372 - val_loss: 235.0936 - val_mae: 12.3605\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 132.0360 - mae: 9.5102 - val_loss: 225.4263 - val_mae: 12.0894\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 135.1937 - mae: 9.5819 - val_loss: 237.3571 - val_mae: 12.4297\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 123.5844 - mae: 9.1572 - val_loss: 220.1498 - val_mae: 11.9520\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 113.4033 - mae: 8.7909 - val_loss: 202.2458 - val_mae: 11.4228\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 138.3725 - mae: 9.7353 - val_loss: 198.7037 - val_mae: 11.3143\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 113.5902 - mae: 8.6822 - val_loss: 210.2155 - val_mae: 11.6503\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 122.6949 - mae: 9.0162 - val_loss: 193.4520 - val_mae: 11.1555\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 116.1406 - mae: 8.8007 - val_loss: 184.9292 - val_mae: 10.9023\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 114.0812 - mae: 8.5263 - val_loss: 188.5177 - val_mae: 11.0157\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 107.1818 - mae: 8.4415 - val_loss: 185.6278 - val_mae: 10.9103\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 105.1258 - mae: 8.2229 - val_loss: 179.3874 - val_mae: 10.7451\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 103.8839 - mae: 8.1541 - val_loss: 168.0877 - val_mae: 10.4123\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 101.4071 - mae: 8.0004 - val_loss: 171.1556 - val_mae: 10.4936\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 89.2889 - mae: 7.6420 - val_loss: 174.4095 - val_mae: 10.5764\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 89.3666 - mae: 7.5820 - val_loss: 164.7034 - val_mae: 10.2485\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 91.5779 - mae: 7.6795 - val_loss: 159.5192 - val_mae: 10.0833\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 85.5308 - mae: 7.3645 - val_loss: 162.7782 - val_mae: 10.1577\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 86.9301 - mae: 7.2418 - val_loss: 160.7465 - val_mae: 10.0800\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 74.2855 - mae: 6.8389 - val_loss: 153.4654 - val_mae: 9.8622\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 69.0602 - mae: 6.6043 - val_loss: 148.4852 - val_mae: 9.7259\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 67.9446 - mae: 6.4995 - val_loss: 174.9799 - val_mae: 10.4431\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 65.3849 - mae: 6.1783 - val_loss: 156.4414 - val_mae: 9.9358\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 61.2453 - mae: 6.1170 - val_loss: 152.9856 - val_mae: 9.7678\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 58.9807 - mae: 6.0409 - val_loss: 142.6074 - val_mae: 9.4600\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 56.2973 - mae: 5.7447 - val_loss: 131.5949 - val_mae: 9.1091\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 54.7833 - mae: 5.6881 - val_loss: 136.2512 - val_mae: 9.2450\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.6131 - mae: 5.5048 - val_loss: 148.5763 - val_mae: 9.5542\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 52.7159 - mae: 5.5624 - val_loss: 130.3480 - val_mae: 9.0214\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.9399 - mae: 5.4295 - val_loss: 124.2179 - val_mae: 8.8395\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 45.1776 - mae: 5.2214 - val_loss: 133.3964 - val_mae: 9.0869\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 49.1027 - mae: 5.2845 - val_loss: 125.5989 - val_mae: 8.8117\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.1068 - mae: 4.6738 - val_loss: 128.7591 - val_mae: 8.8977\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.6185 - mae: 4.5194 - val_loss: 131.9246 - val_mae: 9.0181\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.2043 - mae: 4.9148 - val_loss: 120.3993 - val_mae: 8.6012\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 40.0698 - mae: 4.9712 - val_loss: 127.4462 - val_mae: 8.8884\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.5128 - mae: 4.6498 - val_loss: 120.7083 - val_mae: 8.6507\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 40.5286 - mae: 4.8912 - val_loss: 126.2334 - val_mae: 8.8136\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 39.7503 - mae: 4.7832 - val_loss: 119.8632 - val_mae: 8.7268\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.9623 - mae: 4.4406 - val_loss: 122.4340 - val_mae: 8.7340\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.3635 - mae: 4.6523 - val_loss: 122.6438 - val_mae: 8.7838\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.2334 - mae: 4.4158 - val_loss: 119.2331 - val_mae: 8.5889\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.8502 - mae: 4.2684 - val_loss: 122.0752 - val_mae: 8.8188\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.6538 - mae: 4.5682 - val_loss: 130.6582 - val_mae: 9.0425\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.1025 - mae: 4.3662 - val_loss: 126.0117 - val_mae: 8.8577\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.9233 - mae: 4.7084 - val_loss: 124.0823 - val_mae: 8.8435\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.7315 - mae: 4.4297 - val_loss: 128.6796 - val_mae: 8.9897\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.7585 - mae: 4.4912 - val_loss: 127.8220 - val_mae: 9.0909\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.1823 - mae: 4.2260 - val_loss: 127.0840 - val_mae: 8.9806\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.6852 - mae: 4.2182 - val_loss: 121.8896 - val_mae: 8.7368\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.3472 - mae: 4.3099 - val_loss: 130.4773 - val_mae: 9.1018\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.2330 - mae: 4.2794 - val_loss: 128.8143 - val_mae: 9.0301\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.8246 - mae: 4.1729 - val_loss: 128.5018 - val_mae: 8.9670\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.3639 - mae: 4.3867 - val_loss: 125.7874 - val_mae: 8.9530\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.6646 - mae: 4.3948 - val_loss: 129.2201 - val_mae: 9.0024\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.5271 - mae: 4.0990 - val_loss: 131.6539 - val_mae: 9.1531\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.4400 - mae: 4.0685 - val_loss: 126.3006 - val_mae: 9.0019\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.3038 - mae: 3.9389 - val_loss: 125.2777 - val_mae: 9.0431\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.1863 - mae: 3.9091 - val_loss: 124.7957 - val_mae: 8.9211\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.3526 - mae: 4.0123 - val_loss: 122.7198 - val_mae: 8.8616\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.5789 - mae: 4.0333 - val_loss: 126.7024 - val_mae: 8.9902\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.0093 - mae: 3.8913 - val_loss: 123.7125 - val_mae: 8.9436\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.9463 - mae: 3.9628 - val_loss: 137.7424 - val_mae: 9.2996\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.4330 - mae: 4.0930 - val_loss: 128.4699 - val_mae: 9.0509\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.7931 - mae: 4.0421 - val_loss: 126.8799 - val_mae: 8.9670\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.0019 - mae: 3.7821 - val_loss: 128.5318 - val_mae: 9.1200\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.4933 - mae: 3.6464 - val_loss: 124.7512 - val_mae: 9.0069\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.3037 - mae: 4.1288 - val_loss: 122.9744 - val_mae: 8.8827\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 25.5171 - mae: 3.7792 - val_loss: 127.9297 - val_mae: 9.1118\n",
            "processing fold # 3\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1927.2611 - mae: 40.6541 - val_loss: 455.2885 - val_mae: 18.3894\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1176.0775 - mae: 30.7381 - val_loss: 191.9630 - val_mae: 10.9233\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 352.8232 - mae: 15.3194 - val_loss: 128.2224 - val_mae: 9.0296\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 213.9186 - mae: 11.9884 - val_loss: 131.6877 - val_mae: 9.1827\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 200.7061 - mae: 11.6736 - val_loss: 138.1222 - val_mae: 9.3863\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 193.0892 - mae: 11.6293 - val_loss: 148.9490 - val_mae: 9.6688\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 184.9469 - mae: 11.2432 - val_loss: 160.8359 - val_mae: 10.0102\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 180.4411 - mae: 10.7839 - val_loss: 152.6066 - val_mae: 9.8378\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 145.2877 - mae: 9.9795 - val_loss: 165.4482 - val_mae: 10.2516\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 140.9087 - mae: 9.6845 - val_loss: 181.4489 - val_mae: 10.6820\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 151.9267 - mae: 9.9712 - val_loss: 179.1572 - val_mae: 10.6774\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 125.0403 - mae: 9.0933 - val_loss: 179.9109 - val_mae: 10.6956\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 131.2796 - mae: 9.3562 - val_loss: 177.3201 - val_mae: 10.6411\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 129.5821 - mae: 9.3509 - val_loss: 191.9833 - val_mae: 11.0731\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 125.7137 - mae: 9.0532 - val_loss: 203.1406 - val_mae: 11.2364\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 132.7769 - mae: 9.5665 - val_loss: 199.2986 - val_mae: 11.2320\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 130.6559 - mae: 9.2982 - val_loss: 205.3261 - val_mae: 11.4124\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 122.2282 - mae: 9.0983 - val_loss: 181.0163 - val_mae: 10.8308\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 125.8806 - mae: 9.1622 - val_loss: 182.8346 - val_mae: 10.8829\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 125.9479 - mae: 9.0646 - val_loss: 199.5335 - val_mae: 11.3681\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 123.1141 - mae: 9.1008 - val_loss: 197.7423 - val_mae: 11.3020\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 140.2367 - mae: 9.5411 - val_loss: 210.5859 - val_mae: 11.6773\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 123.6696 - mae: 9.0315 - val_loss: 215.4166 - val_mae: 11.7315\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 125.1028 - mae: 8.9009 - val_loss: 188.4384 - val_mae: 11.0652\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 118.3528 - mae: 8.8602 - val_loss: 195.6716 - val_mae: 11.2510\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 124.5084 - mae: 8.9869 - val_loss: 189.8194 - val_mae: 11.0884\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 119.6700 - mae: 8.9036 - val_loss: 196.6553 - val_mae: 11.2874\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 112.6739 - mae: 8.4081 - val_loss: 194.3994 - val_mae: 11.2199\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 121.7410 - mae: 8.8589 - val_loss: 195.0962 - val_mae: 11.2554\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 128.0525 - mae: 9.0985 - val_loss: 185.9648 - val_mae: 11.0115\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 116.6047 - mae: 8.7250 - val_loss: 214.2007 - val_mae: 11.6992\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 119.7106 - mae: 8.5893 - val_loss: 206.1488 - val_mae: 11.4849\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 119.1980 - mae: 8.8292 - val_loss: 213.6602 - val_mae: 11.6006\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 110.4481 - mae: 8.4222 - val_loss: 199.6256 - val_mae: 11.1974\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 115.8917 - mae: 8.6227 - val_loss: 199.8203 - val_mae: 11.2859\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 109.1971 - mae: 8.4111 - val_loss: 225.3393 - val_mae: 11.8957\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 129.7280 - mae: 9.1184 - val_loss: 209.7467 - val_mae: 11.4958\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 110.5899 - mae: 8.2464 - val_loss: 206.8126 - val_mae: 11.4122\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 122.9314 - mae: 8.7957 - val_loss: 223.6534 - val_mae: 11.7477\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 113.1386 - mae: 8.3270 - val_loss: 192.0174 - val_mae: 10.9292\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 109.3432 - mae: 8.2077 - val_loss: 214.4965 - val_mae: 11.5406\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 109.1113 - mae: 8.2121 - val_loss: 201.2138 - val_mae: 11.2076\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 92.4836 - mae: 7.5354 - val_loss: 178.1865 - val_mae: 10.5657\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 104.2517 - mae: 8.1077 - val_loss: 201.1212 - val_mae: 11.1388\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 118.0633 - mae: 8.3740 - val_loss: 202.7074 - val_mae: 11.1498\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 101.6014 - mae: 7.7712 - val_loss: 188.8895 - val_mae: 10.7660\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 98.4073 - mae: 7.9210 - val_loss: 193.7627 - val_mae: 10.9530\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 84.2555 - mae: 7.1825 - val_loss: 181.9914 - val_mae: 10.6714\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 97.4734 - mae: 7.5810 - val_loss: 183.3914 - val_mae: 10.6189\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 94.2893 - mae: 7.6536 - val_loss: 183.4341 - val_mae: 10.6265\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 86.5831 - mae: 7.2702 - val_loss: 186.7115 - val_mae: 10.6532\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 87.8109 - mae: 7.3899 - val_loss: 189.1631 - val_mae: 10.7629\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 92.4212 - mae: 7.4564 - val_loss: 178.7850 - val_mae: 10.4962\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 86.8950 - mae: 7.4521 - val_loss: 192.6018 - val_mae: 10.9263\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 80.7029 - mae: 7.0457 - val_loss: 176.8207 - val_mae: 10.5242\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 79.5471 - mae: 7.0754 - val_loss: 175.4281 - val_mae: 10.4632\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 93.7822 - mae: 7.5001 - val_loss: 194.0127 - val_mae: 10.9385\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 77.0807 - mae: 7.0149 - val_loss: 179.8267 - val_mae: 10.5738\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 77.1605 - mae: 6.9578 - val_loss: 168.7751 - val_mae: 10.2206\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 82.8926 - mae: 7.3255 - val_loss: 166.6924 - val_mae: 10.1179\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 76.8291 - mae: 7.0330 - val_loss: 160.7834 - val_mae: 9.9292\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 72.0233 - mae: 6.7857 - val_loss: 172.3622 - val_mae: 10.3125\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 75.9600 - mae: 7.0003 - val_loss: 172.6150 - val_mae: 10.3153\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 71.0214 - mae: 6.7689 - val_loss: 171.5248 - val_mae: 10.2510\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 69.3558 - mae: 6.6613 - val_loss: 157.8956 - val_mae: 9.8532\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 73.7364 - mae: 6.8636 - val_loss: 154.9428 - val_mae: 9.7729\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 68.1282 - mae: 6.3503 - val_loss: 165.7905 - val_mae: 10.0963\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 70.8875 - mae: 6.7163 - val_loss: 155.0025 - val_mae: 9.7444\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 66.4857 - mae: 6.4898 - val_loss: 158.5350 - val_mae: 9.8461\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 60.3099 - mae: 6.1476 - val_loss: 156.2034 - val_mae: 9.7399\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.2879 - mae: 6.1348 - val_loss: 140.0885 - val_mae: 9.2718\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 69.1518 - mae: 6.6265 - val_loss: 136.9477 - val_mae: 9.1668\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.5401 - mae: 6.2367 - val_loss: 142.0394 - val_mae: 9.3054\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 63.5101 - mae: 6.2696 - val_loss: 145.1179 - val_mae: 9.4042\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 57.2100 - mae: 6.0609 - val_loss: 131.9687 - val_mae: 8.9479\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 58.8537 - mae: 6.2002 - val_loss: 128.7587 - val_mae: 8.8641\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 63.2915 - mae: 6.2424 - val_loss: 110.3922 - val_mae: 8.1864\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 56.1329 - mae: 5.8327 - val_loss: 133.1335 - val_mae: 9.1046\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 49.8867 - mae: 5.5762 - val_loss: 132.7940 - val_mae: 9.0948\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.3151 - mae: 5.6868 - val_loss: 111.6329 - val_mae: 8.2844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdQhzkx3XB_F"
      },
      "source": [
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VSfzbebZXGFr",
        "outputId": "9255f923-a18c-416c-ff4c-21a58581db7a"
      },
      "source": [
        "plt.plot(range(len(average_mae_history)), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jorfw8a6XIfK",
        "outputId": "c0ac25a9-2bc5-44f3-bf8b-6c265e23e89f"
      },
      "source": [
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 128.3641 - mae: 8.9406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOVzA5oGXJ9m",
        "outputId": "7b22094c-fc20-4539-c904-93ffe0d6133b"
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.940631866455078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}